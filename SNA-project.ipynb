{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ff7cfb4",
   "metadata": {},
   "source": [
    "# How to run?\n",
    "\n",
    "1. Create a folder called \"project\" and put this file and the datasets (all-rnr-annotated-threads and threads). Put source_tweets.csv file inside all-rnr-annotated-threads folder.\n",
    "2. If it complains that you need pip install the imports, do that before continue.\n",
    "3. Remember that some of the parts takes some time (especially graph calculation), so be patient. With less data, it is quicker, so maybe for the visualization, we can choose a subset of dataset. But, it is better to do calculation on whole data in my opinion. We can ask this to Mirela on Wednesday.\n",
    "\n",
    "IDEA: We can create a network by assigning weight to the edges, and see whether unverified news are closer to being true or false. We can also use who follows whom information (we can gather all of them by doing preprocessing)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94197ec2",
   "metadata": {},
   "source": [
    "## Here is some useful links and resources. Those can be directly used for analysis:\n",
    "\n",
    "\n",
    "NetworkX documentation: https://networkx.org/documentation/stable/reference/index.html\n",
    "https://github.com/swkasica/pheme-rnr-knowledge-discovery/blob/master/exploratory_data_analysis.ipynb\n",
    "https://github.com/shakshi12/Rumor-Spreaders-using-GNN-approach-PHEME-dataset-/tree/master/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34d11771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import pytz\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import networkx.algorithms.community as nx_comm\n",
    "from convert_veracity_annotations import convert_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a8503bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/aycavci/Desktop/social-network-analysis/project/all-rnr-annotated-threads\n"
     ]
    }
   ],
   "source": [
    "%cd ../project/all-rnr-annotated-threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ea22fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for source tweets\n",
    "\n",
    "source = pd.read_csv(\"source_tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a34ab9f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>fav_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>account_date</th>\n",
       "      <th>followers</th>\n",
       "      <th>followings</th>\n",
       "      <th>tweet_count</th>\n",
       "      <th>event</th>\n",
       "      <th>is_rumour</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>553529101659566080</td>\n",
       "      <td>BREAKING: Armed man takes hostage in kosher gr...</td>\n",
       "      <td>Fri Jan 09 12:29:56 +0000 2015</td>\n",
       "      <td>14</td>\n",
       "      <td>177</td>\n",
       "      <td>24506246</td>\n",
       "      <td>haaretzcom</td>\n",
       "      <td>Sun Mar 15 09:43:07 +0000 2009</td>\n",
       "      <td>193798</td>\n",
       "      <td>614</td>\n",
       "      <td>63575</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>1</td>\n",
       "      <td>unverified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>553587735613952001</td>\n",
       "      <td>#CharlieHebdo killers dead, confirmed by genda...</td>\n",
       "      <td>Fri Jan 09 16:22:55 +0000 2015</td>\n",
       "      <td>30</td>\n",
       "      <td>134</td>\n",
       "      <td>501768982</td>\n",
       "      <td>AgnesCPoirier</td>\n",
       "      <td>Fri Feb 24 13:18:20 +0000 2012</td>\n",
       "      <td>4709</td>\n",
       "      <td>375</td>\n",
       "      <td>1076</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>1</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>552816932643405824</td>\n",
       "      <td>Top French cartoonists Charb, Cabu, Wolinski, ...</td>\n",
       "      <td>Wed Jan 07 13:20:02 +0000 2015</td>\n",
       "      <td>23</td>\n",
       "      <td>148</td>\n",
       "      <td>47624589</td>\n",
       "      <td>bouckap</td>\n",
       "      <td>Tue Jun 16 13:36:07 +0000 2009</td>\n",
       "      <td>20401</td>\n",
       "      <td>592</td>\n",
       "      <td>7182</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>1</td>\n",
       "      <td>unverified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>553515399438811136</td>\n",
       "      <td>Police have surrounded the area where the #Cha...</td>\n",
       "      <td>Fri Jan 09 11:35:29 +0000 2015</td>\n",
       "      <td>329</td>\n",
       "      <td>684</td>\n",
       "      <td>759251</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Fri Feb 09 00:35:02 +0000 2007</td>\n",
       "      <td>15405096</td>\n",
       "      <td>1038</td>\n",
       "      <td>54427</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>1</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>552808620187217920</td>\n",
       "      <td>PHOTO: Armed gunmen face police officers near ...</td>\n",
       "      <td>Wed Jan 07 12:47:00 +0000 2015</td>\n",
       "      <td>27</td>\n",
       "      <td>113</td>\n",
       "      <td>64643056</td>\n",
       "      <td>RT_com</td>\n",
       "      <td>Tue Aug 11 06:12:45 +0000 2009</td>\n",
       "      <td>842236</td>\n",
       "      <td>460</td>\n",
       "      <td>104998</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>1</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                               text  \\\n",
       "0  553529101659566080  BREAKING: Armed man takes hostage in kosher gr...   \n",
       "1  553587735613952001  #CharlieHebdo killers dead, confirmed by genda...   \n",
       "2  552816932643405824  Top French cartoonists Charb, Cabu, Wolinski, ...   \n",
       "3  553515399438811136  Police have surrounded the area where the #Cha...   \n",
       "4  552808620187217920  PHOTO: Armed gunmen face police officers near ...   \n",
       "\n",
       "                       tweet_date  fav_count  retweet_count    user_id  \\\n",
       "0  Fri Jan 09 12:29:56 +0000 2015         14            177   24506246   \n",
       "1  Fri Jan 09 16:22:55 +0000 2015         30            134  501768982   \n",
       "2  Wed Jan 07 13:20:02 +0000 2015         23            148   47624589   \n",
       "3  Fri Jan 09 11:35:29 +0000 2015        329            684     759251   \n",
       "4  Wed Jan 07 12:47:00 +0000 2015         27            113   64643056   \n",
       "\n",
       "        username                    account_date  followers  followings  \\\n",
       "0     haaretzcom  Sun Mar 15 09:43:07 +0000 2009     193798         614   \n",
       "1  AgnesCPoirier  Fri Feb 24 13:18:20 +0000 2012       4709         375   \n",
       "2        bouckap  Tue Jun 16 13:36:07 +0000 2009      20401         592   \n",
       "3            CNN  Fri Feb 09 00:35:02 +0000 2007   15405096        1038   \n",
       "4         RT_com  Tue Aug 11 06:12:45 +0000 2009     842236         460   \n",
       "\n",
       "   tweet_count                         event  is_rumour      target  \n",
       "0        63575  charliehebdo-all-rnr-threads          1  unverified  \n",
       "1         1076  charliehebdo-all-rnr-threads          1        true  \n",
       "2         7182  charliehebdo-all-rnr-threads          1  unverified  \n",
       "3        54427  charliehebdo-all-rnr-threads          1        true  \n",
       "4       104998  charliehebdo-all-rnr-threads          1        true  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a085ff34",
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = ['charliehebdo-all-rnr-threads', 'ottawashooting-all-rnr-threads', 'ebola-essien-all-rnr-threads',\n",
    "         'prince-toronto-all-rnr-threads', 'ferguson-all-rnr-threads', 'putinmissing-all-rnr-threads',\n",
    "         'germanwings-crash-all-rnr-threads', 'sydneysiege-all-rnr-threads']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18811096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is for reactions. I couldn't manage to write them to .csv file since it is huge\n",
    "# Below are our candidate features, some of them will be dropped\n",
    "\n",
    "tweet_ids = []\n",
    "in_reply_to_tweet_ids = []\n",
    "texts = []\n",
    "tweet_dates = []\n",
    "fav_counts = []\n",
    "retweet_counts = []\n",
    "\n",
    "user_ids = []\n",
    "in_reply_to_user_ids = []\n",
    "usernames = []\n",
    "user_mentions = []\n",
    "mentions = []\n",
    "account_dates = []\n",
    "protected = []\n",
    "verified = []\n",
    "followers = []\n",
    "followings = []\n",
    "tweet_counts = []\n",
    "\n",
    "hashtags = []\n",
    "urls = []\n",
    "\n",
    "events = []\n",
    "is_rumour = []\n",
    "\n",
    "for f in folds:\n",
    "    path1 = os.path.join(f, 'rumours')\n",
    "    for dir1 in os.listdir(path1):\n",
    "        if '_' not in dir1:\n",
    "            path2 = os.path.join(path1, dir1,'reactions')\n",
    "            for dir2 in os.listdir(path2):\n",
    "                if '_' not in dir2:\n",
    "                    path3  = os.path.join(path2, dir2)\n",
    "                    file = open(path3)\n",
    "                    data = json.load(file)\n",
    "\n",
    "                    # tweet features\n",
    "                    tweet_id = int(data['id'])\n",
    "                    in_reply_to_tweet_id = data['in_reply_to_status_id']\n",
    "                    text = data['text']\n",
    "                    tweet_date = data['created_at']\n",
    "                    favs = int(data['favorite_count'])\n",
    "                    retweets = int(data['retweet_count'])\n",
    "\n",
    "                    # user features\n",
    "                    user_id = int(data['user']['id'])\n",
    "                    in_reply_to_user_id = data['in_reply_to_user_id']\n",
    "                    username = data['user']['screen_name']\n",
    "                    user_mention = data['entities']['user_mentions']\n",
    "                    account_date = data['user']['created_at']\n",
    "                    is_protected = data['user']['protected']\n",
    "                    is_verified = data['user']['verified']\n",
    "                    no_followers = int(data['user']['followers_count'])\n",
    "                    no_followings = int(data['user']['friends_count'])\n",
    "                    no_tweets = int(data['user']['statuses_count'])\n",
    "\n",
    "                    # entities\n",
    "                    no_hashtags = int(len(data['entities']['hashtags']))      \n",
    "                    has_url = data['entities']['urls']\n",
    "                    \n",
    "                    # append\n",
    "                    tweet_ids.append(tweet_id)\n",
    "                    in_reply_to_tweet_ids.append(in_reply_to_tweet_id)\n",
    "                    texts.append(text)\n",
    "                    tweet_dates.append(tweet_date)\n",
    "                    fav_counts.append(favs)\n",
    "                    retweet_counts.append(retweets)\n",
    "\n",
    "                    user_ids.append(user_id)\n",
    "                    in_reply_to_user_ids.append(in_reply_to_user_id)\n",
    "                    usernames.append(username)\n",
    "                    for mention in user_mention:\n",
    "                        mentions.append((mention['id'], mention['screen_name']))\n",
    "                    user_mentions.append(mentions)\n",
    "                    account_dates.append(account_date)\n",
    "                    protected.append(is_protected)\n",
    "                    verified.append(is_verified)\n",
    "                    followers.append(no_followers)\n",
    "                    followings.append(no_followings)\n",
    "                    tweet_counts.append(no_tweets)\n",
    "\n",
    "                    hashtags.append(no_hashtags)\n",
    "                    urls.append(has_url)\n",
    "\n",
    "                    is_rumour.append(0)\n",
    "                    events.append(f)\n",
    "                    \n",
    "    path4 = os.path.join(f, 'non-rumours')\n",
    "    for dir3 in os.listdir(path4):\n",
    "        if '_' not in dir3:\n",
    "            path5 = os.path.join(path4, dir3,'reactions')\n",
    "            for dir4 in os.listdir(path5):\n",
    "                if '_' not in dir4:\n",
    "                    path6  = os.path.join(path5, dir4)\n",
    "                    file = open(path6)\n",
    "                    data = json.load(file)\n",
    "\n",
    "                    # tweet features\n",
    "                    tweet_id = int(data['id'])\n",
    "                    in_reply_to_tweet_id = data['in_reply_to_status_id']\n",
    "                    text = data['text']\n",
    "                    tweet_date = data['created_at']\n",
    "                    favs = int(data['favorite_count'])\n",
    "                    retweets = int(data['retweet_count'])\n",
    "\n",
    "                    # user features\n",
    "                    user_id = int(data['user']['id'])\n",
    "                    in_reply_to_user_id = data['in_reply_to_user_id']\n",
    "                    username = data['user']['screen_name']\n",
    "                    user_mention = data['entities']['user_mentions']\n",
    "                    account_date = data['user']['created_at']\n",
    "                    is_protected = data['user']['protected']\n",
    "                    is_verified = data['user']['verified']\n",
    "                    no_followers = int(data['user']['followers_count'])\n",
    "                    no_followings = int(data['user']['friends_count'])\n",
    "                    no_tweets = int(data['user']['statuses_count'])\n",
    "\n",
    "                    # entities\n",
    "                    no_hashtags = int(len(data['entities']['hashtags']))      \n",
    "                    has_url = data['entities']['urls']\n",
    "\n",
    "                    # append\n",
    "                    tweet_ids.append(tweet_id)\n",
    "                    in_reply_to_tweet_ids.append(in_reply_to_tweet_id)\n",
    "                    texts.append(text)\n",
    "                    tweet_dates.append(tweet_date)\n",
    "                    fav_counts.append(favs)\n",
    "                    retweet_counts.append(retweets)\n",
    "\n",
    "                    user_ids.append(user_id)\n",
    "                    in_reply_to_user_ids.append(in_reply_to_user_id)\n",
    "                    usernames.append(username)\n",
    "                    for mention in user_mention:\n",
    "                        mentions.append((mention['id'], mention['screen_name']))\n",
    "                    user_mentions.append(mentions)\n",
    "                    account_dates.append(account_date)\n",
    "                    protected.append(is_protected)\n",
    "                    verified.append(is_verified)\n",
    "                    followers.append(no_followers)\n",
    "                    followings.append(no_followings)\n",
    "                    tweet_counts.append(no_tweets)\n",
    "\n",
    "                    hashtags.append(no_hashtags)\n",
    "                    urls.append(has_url)\n",
    "\n",
    "                    is_rumour.append(0)\n",
    "                    events.append(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6218fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "reactions = pd.DataFrame([tweet_ids, texts, in_reply_to_tweet_ids, tweet_dates, fav_counts, retweet_counts,\n",
    "                          user_ids, in_reply_to_user_ids, usernames, user_mentions, account_dates, protected,\n",
    "                         verified, followers, followings, tweet_counts, hashtags, urls, events, is_rumour], \n",
    "                          ['tweet_id', 'text', 'in_reply_to_tweet_id', 'tweet_date', 'fav_count', 'retweet_count', \n",
    "                           'user_id', 'in_reply_to_user_id', 'username', 'user_mentions', 'account_date', 'protected', \n",
    "                           'verified', 'followers', 'followings', 'tweet_count', 'no_hashtags', 'urls', 'event', \n",
    "                           'is_rumour']).transpose()\n",
    "\n",
    "reactions = reactions.infer_objects()\n",
    "\n",
    "# drop categorical data and protected which has 0 var\n",
    "reactions.drop([\"protected\", \"verified\", \"urls\"], axis=1, inplace=True)\n",
    "\n",
    "reactions = reactions.dropna().reset_index(drop=True)\n",
    "\n",
    "# convert boolen features into numerical\n",
    "reactions = reactions.astype({\"in_reply_to_tweet_id\":'int64', \"in_reply_to_user_id\":'int64'})\n",
    "\n",
    "# reactions.dtypes\n",
    "# reactions.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a439928a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reactions.to_csv('reactions.csv', index=True)\n",
    "# reactions.to_parquet('reactions.parquet.gzip', compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2628558c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>text</th>\n",
       "      <th>in_reply_to_tweet_id</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>fav_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>user_id</th>\n",
       "      <th>in_reply_to_user_id</th>\n",
       "      <th>username</th>\n",
       "      <th>user_mentions</th>\n",
       "      <th>account_date</th>\n",
       "      <th>followers</th>\n",
       "      <th>followings</th>\n",
       "      <th>tweet_count</th>\n",
       "      <th>no_hashtags</th>\n",
       "      <th>event</th>\n",
       "      <th>is_rumour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>553530890908098561</td>\n",
       "      <td>“@haaretzcom: BREAKING: Armed man takes hostag...</td>\n",
       "      <td>553529101659566080</td>\n",
       "      <td>Fri Jan 09 12:37:03 +0000 2015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>269112578</td>\n",
       "      <td>24506246</td>\n",
       "      <td>CapSpaulding01</td>\n",
       "      <td>[(24506246, haaretzcom), (27238485, andreinett...</td>\n",
       "      <td>Sun Mar 20 03:45:28 +0000 2011</td>\n",
       "      <td>1296</td>\n",
       "      <td>1997</td>\n",
       "      <td>102425</td>\n",
       "      <td>0</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>553547184000339968</td>\n",
       "      <td>@haaretzcom @AhmetHez to kill is right? How da...</td>\n",
       "      <td>553529101659566080</td>\n",
       "      <td>Fri Jan 09 13:41:47 +0000 2015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2962507555</td>\n",
       "      <td>24506246</td>\n",
       "      <td>NodrugsRussia</td>\n",
       "      <td>[(24506246, haaretzcom), (27238485, andreinett...</td>\n",
       "      <td>Wed Jan 07 07:00:41 +0000 2015</td>\n",
       "      <td>163</td>\n",
       "      <td>1998</td>\n",
       "      <td>2297</td>\n",
       "      <td>0</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>553546643941761024</td>\n",
       "      <td>@haaretzcom @AhmetHez play back infront of ur ...</td>\n",
       "      <td>553529101659566080</td>\n",
       "      <td>Fri Jan 09 13:39:38 +0000 2015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2962507555</td>\n",
       "      <td>24506246</td>\n",
       "      <td>NodrugsRussia</td>\n",
       "      <td>[(24506246, haaretzcom), (27238485, andreinett...</td>\n",
       "      <td>Wed Jan 07 07:00:41 +0000 2015</td>\n",
       "      <td>163</td>\n",
       "      <td>1998</td>\n",
       "      <td>2297</td>\n",
       "      <td>0</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>553530583583047680</td>\n",
       "      <td>@ohohyesyesnono @haaretzcom Bots will conquest...</td>\n",
       "      <td>553529101659566080</td>\n",
       "      <td>Fri Jan 09 12:35:49 +0000 2015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2856401319</td>\n",
       "      <td>24506246</td>\n",
       "      <td>KingMasterbot</td>\n",
       "      <td>[(24506246, haaretzcom), (27238485, andreinett...</td>\n",
       "      <td>Sun Nov 02 09:16:18 +0000 2014</td>\n",
       "      <td>339</td>\n",
       "      <td>3</td>\n",
       "      <td>113848</td>\n",
       "      <td>0</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>553547846612295681</td>\n",
       "      <td>@haaretzcom @AhmetHez you must be paranoid to ...</td>\n",
       "      <td>553529101659566080</td>\n",
       "      <td>Fri Jan 09 13:44:25 +0000 2015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2962507555</td>\n",
       "      <td>24506246</td>\n",
       "      <td>NodrugsRussia</td>\n",
       "      <td>[(24506246, haaretzcom), (27238485, andreinett...</td>\n",
       "      <td>Wed Jan 07 07:00:41 +0000 2015</td>\n",
       "      <td>163</td>\n",
       "      <td>1998</td>\n",
       "      <td>2297</td>\n",
       "      <td>0</td>\n",
       "      <td>charliehebdo-all-rnr-threads</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id                                               text  \\\n",
       "0  553530890908098561  “@haaretzcom: BREAKING: Armed man takes hostag...   \n",
       "1  553547184000339968  @haaretzcom @AhmetHez to kill is right? How da...   \n",
       "2  553546643941761024  @haaretzcom @AhmetHez play back infront of ur ...   \n",
       "3  553530583583047680  @ohohyesyesnono @haaretzcom Bots will conquest...   \n",
       "4  553547846612295681  @haaretzcom @AhmetHez you must be paranoid to ...   \n",
       "\n",
       "   in_reply_to_tweet_id                      tweet_date  fav_count  \\\n",
       "0    553529101659566080  Fri Jan 09 12:37:03 +0000 2015          0   \n",
       "1    553529101659566080  Fri Jan 09 13:41:47 +0000 2015          0   \n",
       "2    553529101659566080  Fri Jan 09 13:39:38 +0000 2015          0   \n",
       "3    553529101659566080  Fri Jan 09 12:35:49 +0000 2015          0   \n",
       "4    553529101659566080  Fri Jan 09 13:44:25 +0000 2015          0   \n",
       "\n",
       "   retweet_count     user_id  in_reply_to_user_id        username  \\\n",
       "0              0   269112578             24506246  CapSpaulding01   \n",
       "1              0  2962507555             24506246   NodrugsRussia   \n",
       "2              0  2962507555             24506246   NodrugsRussia   \n",
       "3              0  2856401319             24506246   KingMasterbot   \n",
       "4              0  2962507555             24506246   NodrugsRussia   \n",
       "\n",
       "                                       user_mentions  \\\n",
       "0  [(24506246, haaretzcom), (27238485, andreinett...   \n",
       "1  [(24506246, haaretzcom), (27238485, andreinett...   \n",
       "2  [(24506246, haaretzcom), (27238485, andreinett...   \n",
       "3  [(24506246, haaretzcom), (27238485, andreinett...   \n",
       "4  [(24506246, haaretzcom), (27238485, andreinett...   \n",
       "\n",
       "                     account_date  followers  followings  tweet_count  \\\n",
       "0  Sun Mar 20 03:45:28 +0000 2011       1296        1997       102425   \n",
       "1  Wed Jan 07 07:00:41 +0000 2015        163        1998         2297   \n",
       "2  Wed Jan 07 07:00:41 +0000 2015        163        1998         2297   \n",
       "3  Sun Nov 02 09:16:18 +0000 2014        339           3       113848   \n",
       "4  Wed Jan 07 07:00:41 +0000 2015        163        1998         2297   \n",
       "\n",
       "   no_hashtags                         event  is_rumour  \n",
       "0            0  charliehebdo-all-rnr-threads          0  \n",
       "1            0  charliehebdo-all-rnr-threads          0  \n",
       "2            0  charliehebdo-all-rnr-threads          0  \n",
       "3            0  charliehebdo-all-rnr-threads          0  \n",
       "4            0  charliehebdo-all-rnr-threads          0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d9b9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust this according to your path before running!\n",
    "\n",
    "%cd /Users/aycavci/Desktop/social-network-analysis/project/threads/en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21b7fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = ['charliehebdo', 'ottawashooting', 'ebola-essien', 'prince-toronto', 'ferguson', 'putinmissing',\n",
    "           'germanwings-crash', 'sydneysiege']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85751829",
   "metadata": {},
   "outputs": [],
   "source": [
    "who_follows_whom = []\n",
    "count=0\n",
    "\n",
    "for f in folders:\n",
    "    path1 = os.path.join(f)\n",
    "    for dir1 in os.listdir(path1):\n",
    "        if '_' not in dir1:\n",
    "            print(path2)\n",
    "            count+=1\n",
    "            path2  = os.path.join(path1, dir1,'who-follows-whom.dat')\n",
    "            try:\n",
    "                tuples = list(pd.read_table(path2, header=None).itertuples(name=None, index=False))\n",
    "                who_follows_whom.extend(tuples)\n",
    "            except:\n",
    "                continue\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512ea11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directed graph\n",
    "# G = nx.Graph()\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Assign edge\n",
    "# G.add_weighted_edges_from(edges)\n",
    "G.add_edges_from(who_follows_whom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b31100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Network statistics and metrics --\n",
    "\n",
    "print(\"Number of nodes: \", G.number_of_nodes())\n",
    "print(\"Number of edges: \", G.number_of_edges())\n",
    "print(\"Degree distribution: \", G.degree())\n",
    "print(\"In-degree: \", G.in_degree())\n",
    "print(\"Out-degree: \", G.out_degree())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f324685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Centrality indices\n",
    "print(\"Degree centralityt: \", nx.degree_centrality(G))\n",
    "print(\"In-degree centrality: \", nx.in_degree_centrality(G))\n",
    "print(\"Out-degree centrality: \", nx.out_degree_centrality(G))\n",
    "print(\"Betweenness centrality: \", nx.betweenness_centrality(G))\n",
    "print(\"Closeness centrality: \", nx.closeness_centrality(G))\n",
    "centrality = nx.eigenvector_centrality(G)\n",
    "print(\"Eigenvector centrality: \", sorted((v, f\"{c:0.2f}\") for v, c in centrality.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53abdcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering coefficient\n",
    "print(\"Clustering coefficient: \", nx.clustering(G))\n",
    "print(\"Average clustering coefficient: \", nx.average_clustering(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78284d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network diameter and density\n",
    "print(\"Network diameter: \", nx.diameter(G))\n",
    "print(\"Network density: \", nx.density(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bf9118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of connected components and size of connected components\n",
    "print(\"Number of connected components: \", nx.number_connected_components(G))\n",
    "# TODO: We should calculate size of the connected components by ourselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d540cff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Communities --\n",
    "\n",
    "# TODO: Cliques: seems like only for undirected graphs -> https://networkx.org/documentation/stable/reference/algorithms/clique.html\n",
    "# print(\"All cliques: \", list(nx.enumerate_all_cliques(G)))\n",
    "# TODO: Homophily analysis: we need to implement by ourselves -> https://stackoverflow.com/questions/69482619/homophily-in-a-social-network-using-python\n",
    "# Important nodes acting as Bridges\n",
    "print(\"Bridges: \", list(nx.bridges(G)))\n",
    "# Partitioning Algorithm: Girvan-Newman -> https://networkx.org/documentation/stable/reference/algorithms/generated/networkx.algorithms.community.centrality.girvan_newman.html\n",
    "print(\"Girvan-Newman: \", list(nx_comm.girvan_newman(G)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc67ed0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HITS: rank nodes by hub and authority scores\n",
    "h, a = nx.hits(G)\n",
    "print(\"Hub score: \", h)\n",
    "print(\"Authority score: \", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2d4ae2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: Plotting: takes too long. Needs styling. Maybe just skip this for now.\n",
    "plt.figure(figsize=(12, 12))\n",
    "nx.draw(G, with_labels=True, pos=nx.kamada_kawai_layout(G))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c904cc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Longitudinal analysis\n",
    "\n",
    "# Lets take 5 rumours source tweets from each events and see how reactions to those tweets changes in time \n",
    "\n",
    "events = ['charliehebdo-all-rnr-threads', 'ottawashooting-all-rnr-threads', 'ferguson-all-rnr-threads',\n",
    "          'putinmissing-all-rnr-threads', 'germanwings-crash-all-rnr-threads']\n",
    "\n",
    "source_tweet_list = []\n",
    "time_list = []\n",
    "\n",
    "for event in events:\n",
    "    tweet = source.loc[source.event==event].iloc[0]\n",
    "    tweet['tweet_date'] = datetime.strptime(tweet['tweet_date'], '%a %b %d %H:%M:%S %z %Y').replace(tzinfo=None)\n",
    "    source_tweet_list.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b0c89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before running this function for below three cells, you need to change timedelta=minutes for minutes,\n",
    "# timedelta=hours for hours and timedelta=days for days, and run this cell and cell related above.\n",
    "\n",
    "def tweet_counts_by_time(source_tweet_list, reactions, time_begin, time_end):\n",
    "    tweet_reaction_list = []\n",
    "    for tweet in source_tweet_list:\n",
    "        count = 0\n",
    "        for i in range(len(reactions)):\n",
    "            reaction = reactions.iloc[i]\n",
    "            if tweet.event == reaction.event:\n",
    "                time = datetime.strptime(reaction.tweet_date, '%a %b %d %H:%M:%S %z %Y').replace(tzinfo=None)\n",
    "                diff = time-tweet.tweet_date\n",
    "                if (diff > timedelta(minutes=time_begin)) and (diff <= timedelta(minutes=time_end)):\n",
    "                    count+=1\n",
    "        tweet_reaction_list.append(count)\n",
    "    \n",
    "    return tweet_reaction_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968c9e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "minute = tweet_counts_by_time(source_tweet_list, reactions, 0, 1)\n",
    "five_min = tweet_counts_by_time(source_tweet_list, reactions, 0, 5)\n",
    "ten_min = tweet_counts_by_time(source_tweet_list, reactions, 0, 10)\n",
    "thirty_min = tweet_counts_by_time(source_tweet_list, reactions, 0, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e263d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "hour = tweet_counts_by_time(source_tweet_list, reactions, 0, 1)\n",
    "three_hrs = tweet_counts_by_time(source_tweet_list, reactions, 0, 3)\n",
    "eight_hrs = tweet_counts_by_time(source_tweet_list, reactions, 0, 8)\n",
    "twelve_hrs = tweet_counts_by_time(source_tweet_list, reactions, 0, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58343b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "day = tweet_counts_by_time(source_tweet_list, reactions, 0, 1)\n",
    "two_days = tweet_counts_by_time(source_tweet_list, reactions, 0, 2)\n",
    "five_days = tweet_counts_by_time(source_tweet_list, reactions, 0, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f10240",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_list.append(minute)\n",
    "time_list.append(five_min)\n",
    "time_list.append(ten_min)\n",
    "time_list.append(thirty_min)\n",
    "time_list.append(hour)\n",
    "time_list.append(three_hrs)\n",
    "time_list.append(eight_hrs)\n",
    "time_list.append(twelve_hrs)\n",
    "time_list.append(day)\n",
    "time_list.append(two_days)\n",
    "time_list.append(five_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96158df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "charlie_x = ['1 min', '5 min', '10 min', '30 min', '1 hr', '3 hrs', '8 hrs', '12 hrs', '1 day', '2 days', '5 days']\n",
    "ottawa_x = ['1 min', '5 min', '10 min', '30 min', '1 hr', '3 hrs', '8 hrs', '12 hrs', '1 day', '2 days', '5 days']\n",
    "ferguson_x = ['1 min', '5 min', '10 min', '30 min', '1 hr', '3 hrs', '8 hrs', '12 hrs', '1 day', '2 days', '5 days']\n",
    "putin_x = ['1 min', '5 min', '10 min', '30 min', '1 hr', '3 hrs', '8 hrs', '12 hrs', '1 day', '2 days', '5 days']\n",
    "germanwings_x = ['1 min', '5 min', '10 min', '30 min', '1 hr', '3 hrs', '8 hrs', '12 hrs', '1 day', '2 days', '5 days']\n",
    "\n",
    "charlie_y = [time[0] for time in time_list]\n",
    "ottawa_y = [time[1] for time in time_list]\n",
    "ferguson_y= [time[2] for time in time_list]\n",
    "putin_y = [time[3] for time in time_list]\n",
    "germanwings_y = [time[4] for time in time_list]\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "plt.plot(charlie_x, charlie_y, label = \"charliehebdo\")\n",
    "plt.plot(ottawa_x, ottawa_y, label = \"ottawashooting\")\n",
    "plt.plot(ferguson_x, ferguson_y, label = \"ferguson\")\n",
    "plt.plot(putin_x, putin_y, label = \"putinmissing\")\n",
    "plt.plot(germanwings_x, germanwings_y, label = \"germanwings-crash\")\n",
    "\n",
    "plt.xlabel('Timespan')\n",
    "plt.ylabel('Reaction counts (only comments)')\n",
    "plt.title('How reactions to those tweets change in time')\n",
    "  \n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
